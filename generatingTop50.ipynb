{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out top 50 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 50 unique styles based on quantity have been written to top_50_products.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Handle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tarun\\miniconda3\\envs\\load-data-test\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Handle'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m csv_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv_data/top_50_products.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# List all unique values in the column\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mcsv_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHandle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique values in Handle:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_values)\n",
      "File \u001b[1;32mc:\\Users\\tarun\\miniconda3\\envs\\load-data-test\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\tarun\\miniconda3\\envs\\load-data-test\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Handle'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "df = pd.read_csv(\"Ecom_data.csv\")\n",
    "\n",
    "# Ensure QUANTITY is numeric, coercing errors to NaN\n",
    "df['QUANTITY'] = pd.to_numeric(df['QUANTITY'], errors='coerce')\n",
    "\n",
    "# Fill NaN values in QUANTITY with 0 (or handle as needed)\n",
    "df['QUANTITY'] = df['QUANTITY'].fillna(0)\n",
    "\n",
    "# First aggregation: Sum quantities based on STYLE NO. and COLOR\n",
    "aggregated_df = df.groupby(['STYLE NO.', 'COLOR', \"SIZE\"], as_index=False).agg({\n",
    "    'BRAND NAME': 'first',\n",
    "    'QUANTITY': 'sum'\n",
    "})\n",
    "\n",
    "# Second aggregation: Sum quantities based on STYLE NO. to get total quantity for each style\n",
    "style_quantity_df = aggregated_df.groupby('STYLE NO.', as_index=False).agg({\n",
    "    'QUANTITY': 'sum'\n",
    "})\n",
    "\n",
    "# Sort by QUANTITY in descending order and select the top 50 styles\n",
    "top_50_styles = style_quantity_df.sort_values(\n",
    "    by='QUANTITY', ascending=False).head(50)['STYLE NO.']\n",
    "\n",
    "# Filter the original aggregated DataFrame to include only rows corresponding to the top 50 styles\n",
    "top_50_df = aggregated_df[aggregated_df['STYLE NO.'].isin(top_50_styles)]\n",
    "\n",
    "# Write the result to a new CSV file\n",
    "top_50_df.to_csv('csv_data/top_50_products.csv', index=False)\n",
    "\n",
    "print('The top 50 unique styles based on quantity have been written to top_50_products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge TOP 50 CSV and JSON of products to new JSON file with all the variant combinations of SIZE and COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "with open('our_products_new.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_data = pd.read_csv('csv_data/top_50_products.csv')\n",
    "\n",
    "count = 0\n",
    "# Iterate over the CSV rows and update the JSON data\n",
    "for _, row in csv_data.iterrows():\n",
    "    style_no = row['STYLE NO.']\n",
    "    color = row['COLOR']\n",
    "    size = row['SIZE']\n",
    "    quantity = row['QUANTITY']\n",
    "\n",
    "    # Find the matching dict in the JSON data\n",
    "    for item in json_data:\n",
    "        # print(item.get('code'), style_no)\n",
    "\n",
    "        if item.get('code') == style_no:\n",
    "            if 'variants' not in item:\n",
    "                item['variants'] = []\n",
    "            # Add the color, size, and quantity as a new variant\n",
    "            item['variants'].append({\n",
    "                'color': color,\n",
    "                'size': size,\n",
    "                'quantity': quantity\n",
    "            })\n",
    "\n",
    "# # Save the updated list of dicts to a new JSON file\n",
    "with open('updated_data.json', 'w') as output_file:\n",
    "    json.dump(json_data, output_file, indent=4)\n",
    "\n",
    "print('Updated data has been written to updated_data.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Shopify CSV for PRODUCTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Define the required headers for the CSV\n",
    "headers = [\"Handle\", \"Title\", \"Body (HTML)\", \"Description\", \"Vendor\", \"Type\", \"Option1 Name\", \"Option1 Value\", \"Option2 Name\", \"Option2 Value\", \"Variant SKU\", \"Variant Inventory Qty\",\n",
    "           \"Variant Price\", \"Variant Inventory Policy\", \"Variant Requires Shipping\", \"Variant Taxable\", \"Image Src\", \"Variant Inventory Tracker\"]\n",
    "\n",
    "# Load the JSON file\n",
    "with open('updated_data.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Open a new CSV file for writing\n",
    "with open('DEMO_shopify_data_1.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the JSON data to the CSV file\n",
    "    for index, item in enumerate(json_data):\n",
    "        # Create a dictionary for the CSV row\n",
    "        img = item[\"additional_images_url\"][0]\n",
    "        if \"variants\" in item.keys():\n",
    "            for variant in item['variants']:\n",
    "                csv_row = {\n",
    "                    \"Handle\": item.get(\"code\").lower(),\n",
    "                    \"Title\": item.get(\"code\") + \" \" + item.get(\"name\"),\n",
    "                    \"Body (HTML)\": item.get(\"description\"),\n",
    "                    \"Description\": item.get(\"description\"),\n",
    "                    \"Vendor\": \"Milano Formals\",\n",
    "                    \"Type\": \"Dress\",\n",
    "                    \"Option1 Name\": \"Size\",\n",
    "                    \"Option1 Value\": variant['size'],\n",
    "                    \"Option2 Name\": \"Color\",\n",
    "                    \"Option2 Value\": variant['color'],\n",
    "                    \"Variant SKU\": item.get(\"code\") + \"_\" + variant['color'] + \"_\" + variant['size'],\n",
    "                    \"Variant Inventory Tracker\": \"shopify\",\n",
    "                    \"Variant Inventory Qty\": variant['quantity'],\n",
    "                    \"Variant Price\": \"$200\",\n",
    "                    \"Variant Inventory Policy\":  \"deny\",\n",
    "                    \"Variant Requires Shipping\": \"TRUE\",\n",
    "                    \"Variant Taxable\": \"TRUE\",\n",
    "                    \"Image Src\": img,\n",
    "                }\n",
    "                # Write the row to the CSV file\n",
    "                writer.writerow(csv_row)\n",
    "\n",
    "print('JSON data has been converted to CSV and written to output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique 'STYLE NO.': 30\n",
      "Unique values in Handle:\n",
      "['b8865' 'b8998' 'e1168' 'e1260' 'e1264' 'e1270' 'e1285' 'e1295' 'e1340'\n",
      " 'e1379' 'e1420' 'e1421' 'e1463' 'e1502' 'e1520' 'e1531' 'e1544' 'e1581'\n",
      " 'e1582' 'e1657' 'e1663' 'e1696' 'e1729' 'e1730' 'e1796' 'e1799' 'f1116'\n",
      " 'f570' 'e2107' 'e1013']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "# csv_data = pd.read_csv('csv_data/top_50_products_new.csv')\n",
    "# code = \"STYLE NO.\"\n",
    "\n",
    "# csv_data = pd.read_csv('csv_data/shopify_data_new.csv')\n",
    "csv_data = pd.read_csv('DEMO_shopify_data_1.csv')\n",
    "code = \"Handle\"\n",
    "\n",
    "unique_style_no_count = csv_data[code].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of unique 'STYLE NO.': {unique_style_no_count}\")\n",
    "\n",
    "# List all unique values in the column\n",
    "unique_values = csv_data[code].unique()\n",
    "print(f\"Unique values in Handle:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in JSON but not in CSV:\n",
      "{'E2158', 'E2281', 'E2326', 'E2276', 'E2244', 'E2254', 'E2296', 'E2324', 'E1852', 'E1573', 'E2043', 'E2333', 'E2329', 'E2335', 'E2081', 'E2448', 'E2317', 'E2171', 'E2255', 'E1827', 'E1940', 'E2320', 'E2460', 'E2050', 'E2428', 'E2150', 'E2434', 'E2269', 'E1988', 'E2282', 'E1715', 'E2287', 'E2426', 'E2318', 'E2262', 'E1259', 'E2280', 'E2210', 'E2046', 'E2243', 'E1774', 'E2227', 'E2049', 'E2060', 'E2437', 'E2360', 'E2385', 'E2331', 'E1637', 'E2328', 'E2233', 'E2279', 'E2395', 'E2088', 'E2410', 'E2085', 'E2080', 'E1822', 'E2256', 'E2086', 'E2160', 'E2032', 'E2028', 'E1838', 'E2241', 'E1546', 'E1028', 'E2053', 'E2291', 'E2213', 'E2245', 'E2042', 'E2078', 'E2259', 'E2389', 'E2114', 'E2366', 'E2025', 'E2031', 'E2356', 'E2257', 'E2251', 'E1986', 'E2036', 'E2334', 'E2394', 'E2289', 'E2449', 'E2436', 'E1824', 'E2346', 'E2433', 'E2405', 'E2252', 'E2161', 'E2344', 'E2336', 'E2292', 'E1974', 'E2225', 'E2267', 'E1967', 'E2079', 'E2229', 'E2322', 'E2253', 'E2327', 'E2340', 'E2258', 'E2431', 'E2041', 'E2430', 'E2403', 'E2231', 'E2388'}\n",
      "Items in CSV but not in JSON:\n",
      "{'AA9270', 'E1412', '570', 'E1119', 'E1116', 'E2106', 'B8486', '1116', 'E1032', 'B9000', 'E1387', 'G1116', 'E1371', 'BZ570', 'B8608', 'B8808', 'E1312', 'E1024', 'E1068', 'E1391'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "with open('our_products_new.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Extract the 'code' values from the JSON data\n",
    "json_codes = {item['code'] for item in json_data}\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_data = pd.read_csv('csv_data/top_50_products.csv')\n",
    "\n",
    "# Extract the 'STYLE NO.' values from the CSV data\n",
    "csv_codes = set(csv_data['STYLE NO.'])\n",
    "\n",
    "# Find missing items in JSON that are not in CSV\n",
    "missing_in_json = json_codes - csv_codes\n",
    "\n",
    "# Find missing items in CSV that are not in JSON\n",
    "missing_in_csv = csv_codes - json_codes\n",
    "\n",
    "print(\"Items in JSON but not in CSV:\")\n",
    "print(missing_in_json)\n",
    "\n",
    "print(\"Items in CSV but not in JSON:\")\n",
    "print(missing_in_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load-data-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
