{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access your secret using os.getenv\n",
    "OPEN_AI_API = os.getenv(\"OPEN_AI_API\")\n",
    "print(OPEN_AI_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 24751 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Error: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 24740 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Improved descriptions saved. ../../data/product_data/product_data.csv\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "api_key = OPEN_AI_API\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def improve_description(description):\n",
    "    try:\n",
    "        # Call OpenAI API to improve the description\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a product description assistant that writes engaging and high-quality descriptions for fashion items. \"\n",
    "                        \"Each description should be 4-6 sentences, highlighting the style, material, unique features, and ideal occasions \"\n",
    "                        \"for wearing the item. Maintain proper grammar and punctuation. Please do not use similar sentence structure. \"\n",
    "                        \"Try to use different action words for each output and make it more creative.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Please write a detailed and engaging description for the following dress:\\n\\n{description}\"\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        # Extract the improved description from the API response\n",
    "        improved_text = response.choices[0].message.content\n",
    "        return improved_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return description  # Return the original description if there's an error\n",
    "\n",
    "# Load descriptions from CSV\n",
    "input_file = \"../../data/product_data/product_data.csv\"\n",
    "df = pd.read_csv(input_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Create a new column for improved descriptions\n",
    "df['ai_description'] = \"\"\n",
    "\n",
    "# Process descriptions, with a counter to limit processing to 10 descriptions\n",
    "# processed_count = 0\n",
    "for index, row in df.iterrows():\n",
    "    description = row['Description']\n",
    "\n",
    "    if pd.notna(description) and description.strip():\n",
    "        improved_desc = improve_description(description)\n",
    "        df.at[index, 'ai_description'] = improved_desc\n",
    "        # processed_count += 1\n",
    "\n",
    "        # if processed_count >= 10:\n",
    "        #     break  # Stop after processing 10 descriptions\n",
    "\n",
    "        time.sleep(1)  # Delay after each API call\n",
    "    else:\n",
    "        df.at[index, 'ai_description'] = \"\"  # Keep empty description if original was empty\n",
    "\n",
    "# Save the updated DataFrame back to the same file\n",
    "df.to_csv(input_file, index=False)\n",
    "print(\"Improved descriptions saved.\", input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### File_Name renamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file has been saved to ../../data/product_data/shopify_urls_copy.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '../../data/product_data/shopify_urls_copy.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Function to standardize file_name\n",
    "def standardize_file_name(file_name):\n",
    "    # Regular expression to capture CODE, COLOR, and NUMBER\n",
    "    match = re.match(r\"^([A-Z0-9]+)_([A-Za-z-_]+)_(\\d+)\", file_name)\n",
    "    if match:\n",
    "        code = match.group(1)\n",
    "        color = match.group(2).replace('_', '-')  # Replace underscores with hyphens\n",
    "        number = match.group(3)\n",
    "\n",
    "        # Capitalize each word in color\n",
    "        color = '-'.join([word.upper() for word in color.split('-')])\n",
    "\n",
    "        # Reformat the file_name to CODE_COLOR_NUMBER\n",
    "        standardized_file_name = f\"{code}_{color}_{number} PNG\"\n",
    "        return standardized_file_name\n",
    "    else:\n",
    "        return file_name  # If it doesn't match, return the original\n",
    "\n",
    "# Apply the function to the 'file_name' column\n",
    "df['file_name'] = df['file_name'].apply(standardize_file_name)\n",
    "\n",
    "# Save the updated DataFrame back to the same file\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"Updated file has been saved to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecomm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
