{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 1: Get the Style code, color, quantity, and size from the main sheet into a new sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "Selected columns have been written to ../../data/Homecoming/filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = '../../data/product_data/main_sheet.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Rename specific columns\n",
    "df = df.rename(columns={\n",
    "    'Handle': 'Handle',\n",
    "    'SIZE_US': 'Size',\n",
    "    'COLOR': 'Color',\n",
    "    'QUANTITY': 'Quantity',\n",
    "    'BRAND NAME': 'Brand',\n",
    "})\n",
    "\n",
    "# Define validation criteria for each column\n",
    "\n",
    "\n",
    "def validate_row(row):\n",
    "    # Check for missing or blank values\n",
    "    if pd.isnull(row['Brand']) or pd.isnull(row['Handle']) or pd.isnull(row['Color']) or pd.isnull(row['Quantity']) or pd.isnull(row['Size']):\n",
    "        return False\n",
    "    if row['Brand'].strip() == '' or row['Handle'].strip() == '' or row['Color'].strip() == '':\n",
    "        return False\n",
    "\n",
    "    # Check for correct data types\n",
    "    if not isinstance(row['Brand'], str) or not isinstance(row['Handle'], str) or not isinstance(row['Color'], str):\n",
    "        return False\n",
    "    try:\n",
    "        float(row['Quantity'])\n",
    "        float(row['Size'])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Apply validation to each row\n",
    "valid_rows = df.apply(validate_row, axis=1)\n",
    "\n",
    "# Filter the DataFrame to retain only valid rows\n",
    "filtered_df = df[valid_rows]\n",
    "\n",
    "\n",
    "\n",
    "# Select the specified columns based on the new names\n",
    "selected_columns = ['Handle', 'Brand', 'Color', 'Quantity', 'Size']\n",
    "new_df = filtered_df[selected_columns]\n",
    "\n",
    "# Write the filtered data to a new CSV file\n",
    "# output_file = '../../scripts/catalog/filtered_data.csv'\n",
    "output_file = '../../data/Homecoming/filtered_data.csv'\n",
    "new_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print number of unique Codes\n",
    "print(new_df['Handle'].nunique())\n",
    "print(f\"Selected columns have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2: Group this sheet by style code, color, and size and sum of quantity by group to get the total quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Codes in the original DataFrame: 559\n",
      "Number of unique Codes after aggregation: 559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "df = pd.read_csv(\"../../data/Homecoming/filtered_data.csv\")\n",
    "\n",
    "# Ensure Quantity is numeric, coercing errors to NaN\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "\n",
    "# Fill NaN values in Quantity with 0 (or handle as needed)\n",
    "df['Quantity'] = df['Quantity'].fillna(0)\n",
    "\n",
    "# First aggregation: Sum quantities based on Code, Color, and Size\n",
    "aggregated_df = df.groupby(['Handle', 'Color', 'Size'], as_index=False).agg({\n",
    "    'Brand': 'first',  # Assuming you want to keep the first Brand name found\n",
    "    'Quantity': 'sum'\n",
    "})\n",
    "\n",
    "# Print the number of unique codes after aggregation\n",
    "print(f\"Number of unique Codes in the original DataFrame: {\n",
    "      df['Handle'].nunique()}\")\n",
    "print(f\"Number of unique Codes after aggregation: {\n",
    "      aggregated_df['Handle'].nunique()}\")\n",
    "\n",
    "# Write the aggregated data to a new CSV file\n",
    "aggregated_df.to_csv('../../data/Homecoming/step_2_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3: Get the prices and Description of available product codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file has been saved to ../../data/Homecoming/step_3_output.csv\n",
      "Number of unique handles: 59\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Homecoming CSV file\n",
    "homecoming_file_path = '../../data/product_data/Homecoming.csv'\n",
    "homecoming_df = pd.read_csv(homecoming_file_path)\n",
    "\n",
    "# Load the step_2_output CSV file\n",
    "step2_file_path = '../../data/Homecoming/step_2_output.csv'\n",
    "step2_df = pd.read_csv(step2_file_path)\n",
    "\n",
    "# Remove duplicates from Homecoming based on 'Handle'\n",
    "homecoming_df = homecoming_df.drop_duplicates(subset=['Handle'], keep='first')\n",
    "\n",
    "# Merge the two DataFrames on the 'Handle' column to get both 'Price' and 'Description' from Homecoming\n",
    "merged_df = pd.merge(step2_df, homecoming_df[['Handle', 'Price', 'Description']], on='Handle', how='left')\n",
    "\n",
    "# Keep only the rows where both 'Price' and 'Description' are not missing\n",
    "filtered_df = merged_df.dropna(subset=['Price', 'Description'])\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "output_file_path = '../../data/Homecoming/step_3_output.csv'\n",
    "filtered_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Print the number of unique handles in the filtered data\n",
    "print(f\"Filtered file has been saved to {output_file_path}\")\n",
    "print(f\"Number of unique handles: {filtered_df['Handle'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 5: Combine image URLs with the product code and add additional URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "Final CSV file with appended URLs has been saved to ../../data/Homecoming/step_5_output.csv\n",
      "Number of unique handles: 53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "file1_path = '../../data/Homecoming/step_3_output.csv'\n",
    "file2_path = '../../data/product_data/s3_urls.csv'  # Replace with the actual file path\n",
    "\n",
    "file1 = pd.read_csv(file1_path)\n",
    "file2 = pd.read_csv(file2_path)\n",
    "\n",
    "print(file2['Handle'].nunique())\n",
    "\n",
    "# Merge the two DataFrames on the 'Handle' column\n",
    "merged_df = pd.merge(file1, file2[['Handle', 'url']], on='Handle', how='left')\n",
    "\n",
    "# Group URLs by 'Handle' and create a list of URLs for each 'Handle'\n",
    "url_grouped = file2.groupby('Handle')['url'].apply(lambda x: ','.join(x)).reset_index()\n",
    "\n",
    "# Merge the grouped URLs back to the original DataFrame\n",
    "final_df = pd.merge(file1, url_grouped, on='Handle', how='left')\n",
    "\n",
    "# Rename the 'url' column to 'Urls'\n",
    "final_df = final_df.rename(columns={'url': 'Urls'})\n",
    "\n",
    "# Discard rows where 'Urls' is NaN (no URL available)\n",
    "final_df = final_df.dropna(subset=['Urls'])\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "output_file_path = '../../data/Homecoming/step_5_output.csv'\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Final CSV file with appended URLs has been saved to {output_file_path}\")\n",
    "print(f\"Number of unique handles: {final_df['Handle'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 6: Creating shopify csv file to upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "Shopify CSV file has been saved to ../../data/shopify_sheets/Homecoming_shopify_output_demo.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "# Replace with the actual file path\n",
    "file1_path = '../../data/Homecoming/step_5_output.csv'\n",
    "\n",
    "\n",
    "file1 = pd.read_csv(file1_path)\n",
    "\n",
    "\n",
    "# Create Shopify CSV structure\n",
    "\n",
    "\n",
    "shopify_columns = ['Handle', 'Title', 'Body (HTML)', 'Vendor', 'Type', 'Tags', 'Published', 'Option1 Name', 'Option1 Value', 'Option2 Name', 'Option2 Value', 'Variant SKU', 'Variant Grams', 'Variant Inventory Tracker', 'Variant Inventory Qty', 'Variant Inventory Policy', 'Variant Fulfillment Service', 'Variant Price', 'Variant Compare at Price', 'Variant Requires Shipping', 'Variant Taxable', 'Variant Barcode', 'Image Src', 'Image Position',\n",
    "\n",
    "\n",
    "\n",
    "                   'Image Alt Text'\n",
    "\n",
    "\n",
    "\n",
    "                   ]\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "\n",
    "\n",
    "shopify_df = pd.DataFrame(columns=shopify_columns)\n",
    "all_entries = []\n",
    "\n",
    "current_code = None\n",
    "\n",
    "other_images = []\n",
    "\n",
    "\n",
    "# def check_sleeve_preference(combined_list):\n",
    "#     # Define sleeve-related terms\n",
    "#     sleeve_terms = [\"Sleeveless\", \"Short Sleeve\",\n",
    "#                     \"Long Sleeve\", \"Spaghetti Strap\"]\n",
    "\n",
    "#     # Check for the presence of sleeve terms\n",
    "#     found_sleeves = set()\n",
    "#     for term in sleeve_terms:\n",
    "#         # Check each column in the row for the term\n",
    "#         if any(re.search(rf'\\b{term}\\b', col, re.IGNORECASE) for col in combined_list):\n",
    "#             found_sleeves.add(term)\n",
    "\n",
    "#     # Determine the preferred sleeve term\n",
    "#     if \"Spaghetti Strap\" in found_sleeves:\n",
    "#         return \"Spaghetti Strap\"\n",
    "#     elif \"Short Sleeve\" in found_sleeves:\n",
    "#         return \"Short Sleeve\"\n",
    "#     elif found_sleeves:\n",
    "#         # Return any other found term if Spaghetti Strap or Short Sleeve is not found\n",
    "#         return list(found_sleeves)[0]\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# Iterate over rows using iterrows()\n",
    "for index, row in file1.iterrows():\n",
    "\n",
    "    # Check if we have encountered a new code\n",
    "\n",
    "    if current_code is not None and current_code != row['Handle']:\n",
    "\n",
    "        # Append additional images for the previous code\n",
    "\n",
    "        for idx, url in enumerate(other_images):\n",
    "\n",
    "            image_entry = {'Handle': current_code.lower(),\n",
    "                           'Image Src': url,\n",
    "                           'Image Position': idx + 2, }\n",
    "\n",
    "            all_entries.append(pd.DataFrame([image_entry]))\n",
    "\n",
    "        # Reset the other_images list for the new code\n",
    "\n",
    "        other_images = []\n",
    "\n",
    "    # Set the current code\n",
    "\n",
    "    # current_code = row['Code']\n",
    "    current_code = row['Handle']\n",
    "\n",
    "    # Generate handle from product name\n",
    "\n",
    "    # keywords = str(row['Keywords']) if pd.notna(row['Keywords']) else ''\n",
    "\n",
    "    # if keywords != '':\n",
    "\n",
    "    #     keywords = keywords.split(\", \")\n",
    "    #     meta_features = \", \".join(keywords)\n",
    "\n",
    "    # description = str(row['Long Description']) if pd.notna(\n",
    "    #     row['Long Description']) else ''\n",
    "\n",
    "    # body_html = f'<p>{description}</p>\\n<ul>'\n",
    "    body_html = f'<p>{row['Description']}</p>'\n",
    "\n",
    "    # for i in range(0, len(keywords)):\n",
    "\n",
    "    #     body_html += f'\\n<li>{keywords[i]}</li>'\n",
    "\n",
    "    # body_html += '\\n</ul>'\n",
    "\n",
    "    if isinstance(row['Urls'], str):\n",
    "\n",
    "        all_images = row['Urls'].split(\",\")\n",
    "\n",
    "        first_image, *other_images = all_images\n",
    "\n",
    "    # else:\n",
    "\n",
    "    #     continue\n",
    "\n",
    "    # title = row['Title'] + \" \" + row['Code']\n",
    "    # title = title.replace('\"', \"\")\n",
    "    # title = re.sub(r'\\s+', ' ', title)\n",
    "\n",
    "    # temp_extract = [row['Occasions'], row['Keywords'],  row['Tags']]\n",
    "\n",
    "    # meta_sleeve_length_type = check_sleeve_preference(temp_extract)\n",
    "\n",
    "    # Create a new row for the main product entry\n",
    "\n",
    "    product_entry = {\n",
    "\n",
    "\n",
    "\n",
    "        'Handle': row['Handle'].lower(),\n",
    "\n",
    "\n",
    "\n",
    "        'Title': \"Nova Vogue \" +  row['Handle'],\n",
    "\n",
    "\n",
    "\n",
    "        'Body (HTML)': body_html,\n",
    "\n",
    "\n",
    "\n",
    "        'Vendor': \"Nova Vogue\",\n",
    "        # 'Vendor': row['Brand'],\n",
    "\n",
    "\n",
    "\n",
    "        # 'Type': row['Dress Type'],  # You can customize this\n",
    "        'Type': 'Short',  # You can customize this\n",
    "\n",
    "\n",
    "\n",
    "        'Tags': \"Homecoming, Homecoming 2024, Short Dress\",\n",
    "\n",
    "\n",
    "\n",
    "        'Published': 'TRUE',\n",
    "\n",
    "\n",
    "\n",
    "        \"Product Category\": \"Apparel & Accessories > Clothing > Dresses\",\n",
    "\n",
    "\n",
    "\n",
    "        'Option1 Name': 'Color',\n",
    "\n",
    "\n",
    "\n",
    "        'Option1 Value': row['Color'],\n",
    "\n",
    "\n",
    "\n",
    "        'Option2 Name': 'Size',\n",
    "\n",
    "\n",
    "\n",
    "        'Option2 Value': row['Size'],\n",
    "\n",
    "\n",
    "\n",
    "        'Variant SKU': f\"{row['Handle']}_{row['Color'].upper()}_{row['Size']}\",\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Grams': '',  # Add weight if available\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Inventory Tracker': 'shopify',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Inventory Qty': row['Quantity'],\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Inventory Policy': 'deny',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Fulfillment Service': 'manual',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Price': row['Price'],\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Compare at Price': '',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Requires Shipping': 'TRUE',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Taxable': 'TRUE',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Barcode': '',\n",
    "\n",
    "\n",
    "\n",
    "        'Image Src': first_image,  # First image URL\n",
    "\n",
    "\n",
    "\n",
    "        'Image Position': 1,\n",
    "\n",
    "\n",
    "\n",
    "        # 'Image Alt Text': \"Nova Vogue \" + str(row['Handle']).lower() + \" \" + row['Description'],\n",
    "        'Image Alt Text': \"Nova Vogue CODE: {} Color: {} Size: {}\".format(str(row['Handle']).lower(), str(row['Color']).lower(), str(row['Size']).lower()),\n",
    "        # 'metafield.custom.clothing_features': meta_features,\n",
    "        # 'metafield.custom.dress_occasion': re.sub(r'\\s+', ' ', row['Occasions']),\n",
    "        'metafield.custom.dress_style': \"Short Dress \" + row['Handle'].upper(),\n",
    "        'metafield.custom.skirt_dress_length_type': \"Short\",\n",
    "        # 'metafield.custom.sleeve_length_type': meta_sleeve_length_type\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # Add the main product entry to the list\n",
    "\n",
    "    all_entries.append(pd.DataFrame([product_entry]))\n",
    "\n",
    "\n",
    "# Append additional images for the last code\n",
    "\n",
    "\n",
    "if other_images:\n",
    "\n",
    "    for idx, url in enumerate(other_images):\n",
    "\n",
    "        image_entry = {\n",
    "\n",
    "\n",
    "\n",
    "            'Handle': current_code.lower(),\n",
    "\n",
    "\n",
    "\n",
    "            'Image Src': url,\n",
    "\n",
    "\n",
    "\n",
    "            'Image Position': idx + 2,  # Start from position 2\n",
    "\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "        all_entries.append(pd.DataFrame([image_entry]))\n",
    "\n",
    "\n",
    "# Concatenate all entries into a single DataFrame\n",
    "\n",
    "\n",
    "shopify_df = pd.concat(all_entries, ignore_index=True)\n",
    "\n",
    "\n",
    "print(shopify_df['Handle'].nunique())\n",
    "output_file_path = '../../data/shopify_sheets/Homecoming_shopify_output_demo.csv'\n",
    "shopify_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Shopify CSV file has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some verificatiosn for understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load-data-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
