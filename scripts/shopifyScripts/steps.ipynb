{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 1: Get the Style code, color, quantity, and size from the main sheet into a new sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\n",
      "Selected columns have been written to ../../data/sheets/filtered_main_sheet.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = '../../data/sheets/main_sheet.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Rename specific columns\n",
    "df = df.rename(columns={\n",
    "    'STYLE NO.': 'Code',\n",
    "    'SIZE_US': 'Size',\n",
    "    'COLOR': 'Color',\n",
    "    'QUANTITY': 'Quantity',\n",
    "    'BRAND NAME': 'Brand'\n",
    "})\n",
    "\n",
    "# Define validation criteria for each column\n",
    "def validate_row(row):\n",
    "    # Check for missing or blank values\n",
    "    if pd.isnull(row['Brand']) or pd.isnull(row['Code']) or pd.isnull(row['Color']) or pd.isnull(row['Quantity']) or pd.isnull(row['Size']):\n",
    "        return False\n",
    "    if row['Brand'].strip() == '' or row['Code'].strip() == '' or row['Color'].strip() == '':\n",
    "        return False\n",
    "\n",
    "    # Check for correct data types\n",
    "    if not isinstance(row['Brand'], str) or not isinstance(row['Code'], str) or not isinstance(row['Color'], str):\n",
    "        return False\n",
    "    try:\n",
    "        float(row['Quantity'])\n",
    "        float(row['Size'])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Apply validation to each row\n",
    "valid_rows = df.apply(validate_row, axis=1)\n",
    "\n",
    "# Filter the DataFrame to retain only valid rows\n",
    "filtered_df = df[valid_rows]\n",
    "\n",
    "# Select the specified columns based on the new names\n",
    "selected_columns = ['Brand', 'Code', 'Color', 'Quantity', 'Size']\n",
    "new_df = filtered_df[selected_columns]\n",
    "\n",
    "# Write the filtered data to a new CSV file\n",
    "output_file = '../../data/sheets/filtered_main_sheet.csv'\n",
    "new_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print number of unique Codes\n",
    "print(new_df['Code'].nunique())\n",
    "print(f\"Selected columns have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2: Group this sheet by style code, color, and size and sum of quantity by group to get the total quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Codes in the original DataFrame: 558\n",
      "Number of unique Codes after aggregation: 558\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "df = pd.read_csv(\"../../data/sheets/filtered_main_sheet.csv\")\n",
    "\n",
    "# Ensure Quantity is numeric, coercing errors to NaN\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "\n",
    "# Fill NaN values in Quantity with 0 (or handle as needed)\n",
    "df['Quantity'] = df['Quantity'].fillna(0)\n",
    "\n",
    "# First aggregation: Sum quantities based on Code, Color, and Size\n",
    "aggregated_df = df.groupby(['Code', 'Color', 'Size'], as_index=False).agg({\n",
    "    'Brand': 'first',  # Assuming you want to keep the first Brand name found\n",
    "    'Quantity': 'sum'\n",
    "})\n",
    "\n",
    "# Print the number of unique codes after aggregation\n",
    "print(f\"Number of unique Codes in the original DataFrame: {df['Code'].nunique()}\")\n",
    "print(f\"Number of unique Codes after aggregation: {aggregated_df['Code'].nunique()}\")\n",
    "\n",
    "# Write the aggregated data to a new CSV file\n",
    "aggregated_df.to_csv('../../data/sheets/step_2_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3: Get the prices of available product codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\n",
      "Updated file has been saved to ../../data/sheets/step_3_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file\n",
    "# Replace with your actual file path\n",
    "file1_path = '../../data/transformed_products.csv'\n",
    "file1 = pd.read_csv(file1_path)\n",
    "\n",
    "# Load the second CSV file\n",
    "# Replace with your actual file path\n",
    "file2_path = '../../data/sheets/step_2_output.csv'\n",
    "file2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Merge the two DataFrames on the 'Code' column to get the 'Price' column from file1\n",
    "merged_df = pd.merge(file2, file1[['Code', 'Price']], on='Code', how='left')\n",
    "\n",
    "# Update the 'Price' column in file2 with the values from the merged DataFrame\n",
    "file2['Price'] = merged_df['Price']\n",
    "\n",
    "# Save the updated file2 DataFrame to a new CSV file\n",
    "# Replace with your desired output file path\n",
    "output_file_path = '../../data/sheets/step_3_output.csv'\n",
    "\n",
    "print(merged_df['Code'].nunique())\n",
    "file2.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Updated file has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 4: Combine title, description, keywords, and tags with this new sheet based on product code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "Merged file has been saved to ../../data/sheets/step_4_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file (file_1)\n",
    "# Replace with the actual file path\n",
    "file1_path = '../../data/sheets/product_info_final.csv'\n",
    "file1 = pd.read_csv(file1_path)\n",
    "# removing copies\n",
    "file1 = file1.drop_duplicates(subset=['Code'], keep='first')\n",
    "# Load the second CSV file (file_2)\n",
    "# Replace with the actual file path\n",
    "file2_path = '../../data/sheets/step_3_output.csv'\n",
    "file2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Remove 'Color' column from file_1 if it exists\n",
    "if 'Color' in file1.columns:\n",
    "    file1 = file1.drop(columns=['Color'])\n",
    "\n",
    "# Merge the two DataFrames on the 'Code' column, keeping details from file_1\n",
    "merged_df = pd.merge(file2, file1, on='Code', how='inner')\n",
    "\n",
    "# Define the columns from file_1 to copy to file_2\n",
    "columns_to_copy = ['Title', 'Long Description', 'Short Description',\n",
    "                   'Dress Type', 'Occasions', 'Keywords', 'Tags']\n",
    "\n",
    "# For each column to copy, fill NaN values in merged_df with the corresponding values from file_1\n",
    "for column in columns_to_copy:\n",
    "    merged_df[column] = merged_df.groupby('Code')[column].transform('first')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "# Replace with your desired output file path\n",
    "output_file_path = '../../data/sheets/step_4_output.csv'\n",
    "print(merged_df['Code'].nunique())\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Merged file has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 5: Combine image URLs with the product code and add additional URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "Final CSV file with appended URLs has been saved to ../../data/sheets/step_5_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "# Replace with the actual file path\n",
    "file1_path = '../../data/sheets/step_4_output.csv'\n",
    "file2_path = '../../data/s3_url_images.csv'  # Replace with the actual file path\n",
    "\n",
    "file1 = pd.read_csv(file1_path)\n",
    "file2 = pd.read_csv(file2_path)\n",
    "\n",
    "print(file2['Product Code'].nunique())\n",
    "# Rename columns in file2 to match the columns in file1 for merging\n",
    "file2 = file2.rename(columns={'Product Code': 'Code'})\n",
    "\n",
    "# Merge the two DataFrames on the 'Code' column\n",
    "merged_df = pd.merge(file1, file2[['Code', 'url']], on='Code', how='left')\n",
    "\n",
    "# Group URLs by 'Code' and create a list of URLs for each 'Code'\n",
    "url_grouped = file2.groupby('Code')['url'].apply(\n",
    "    lambda x: ','.join(x)).reset_index()\n",
    "\n",
    "# Merge the grouped URLs back to the original DataFrame\n",
    "final_df = pd.merge(file1, url_grouped, on='Code', how='left')\n",
    "final_df = final_df.rename(columns={'url': 'Urls'})\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "# Replace with your desired output file path\n",
    "output_file_path = '../../data/sheets/step_5_output.csv'\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Final CSV file with appended URLs has been saved to {\n",
    "      output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 6: Creating shopify csv file to upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "Shopify CSV file has been saved to ../../data/sheets/shopify_output_demo.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "# Replace with the actual file path\n",
    "file1_path = '../../data/sheets/step_5_output.csv'\n",
    "\n",
    "\n",
    "file1 = pd.read_csv(file1_path)\n",
    "\n",
    "\n",
    "# Create Shopify CSV structure\n",
    "\n",
    "\n",
    "shopify_columns = ['Handle', 'Title', 'Body (HTML)', 'Vendor', 'Type', 'Tags', 'Published', 'Option1 Name', 'Option1 Value', 'Option2 Name', 'Option2 Value', 'Variant SKU', 'Variant Grams', 'Variant Inventory Tracker', 'Variant Inventory Qty', 'Variant Inventory Policy', 'Variant Fulfillment Service', 'Variant Price', 'Variant Compare at Price', 'Variant Requires Shipping', 'Variant Taxable', 'Variant Barcode', 'Image Src', 'Image Position',\n",
    "\n",
    "\n",
    "\n",
    "                   'Image Alt Text'\n",
    "\n",
    "\n",
    "\n",
    "                   ]\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "\n",
    "\n",
    "shopify_df = pd.DataFrame(columns=shopify_columns)\n",
    "all_entries = []\n",
    "\n",
    "current_code = None\n",
    "\n",
    "other_images = []\n",
    "\n",
    "\n",
    "def check_sleeve_preference(combined_list):\n",
    "    # Define sleeve-related terms\n",
    "    sleeve_terms = [\"Sleeveless\", \"Short Sleeve\",\n",
    "                    \"Long Sleeve\", \"Spaghetti Strap\"]\n",
    "\n",
    "    # Check for the presence of sleeve terms\n",
    "    found_sleeves = set()\n",
    "    for term in sleeve_terms:\n",
    "        # Check each column in the row for the term\n",
    "        if any(re.search(rf'\\b{term}\\b', col, re.IGNORECASE) for col in combined_list):\n",
    "            found_sleeves.add(term)\n",
    "\n",
    "    # Determine the preferred sleeve term\n",
    "    if \"Spaghetti Strap\" in found_sleeves:\n",
    "        return \"Spaghetti Strap\"\n",
    "    elif \"Short Sleeve\" in found_sleeves:\n",
    "        return \"Short Sleeve\"\n",
    "    elif found_sleeves:\n",
    "        # Return any other found term if Spaghetti Strap or Short Sleeve is not found\n",
    "        return list(found_sleeves)[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Iterate over rows using iterrows()\n",
    "for index, row in file1.iterrows():\n",
    "\n",
    "    # Check if we have encountered a new code\n",
    "\n",
    "    if current_code is not None and current_code != row['Code']:\n",
    "\n",
    "        # Append additional images for the previous code\n",
    "\n",
    "        for idx, url in enumerate(other_images):\n",
    "\n",
    "            image_entry = {'Handle': current_code.lower(),\n",
    "                           'Image Src': url,\n",
    "                           'Image Position': idx + 2, }\n",
    "\n",
    "            all_entries.append(pd.DataFrame([image_entry]))\n",
    "\n",
    "        # Reset the other_images list for the new code\n",
    "\n",
    "        other_images = []\n",
    "\n",
    "    # Set the current code\n",
    "\n",
    "    current_code = row['Code']\n",
    "\n",
    "    # Generate handle from product name\n",
    "\n",
    "    keywords = str(row['Keywords']) if pd.notna(row['Keywords']) else ''\n",
    "\n",
    "    if keywords != '':\n",
    "\n",
    "        keywords = keywords.split(\", \")\n",
    "        meta_features = \", \".join(keywords)\n",
    "\n",
    "    description = str(row['Long Description']) if pd.notna(\n",
    "        row['Long Description']) else ''\n",
    "\n",
    "    body_html = f'<p>{description}</p>\\n<ul>'\n",
    "\n",
    "    for i in range(0, len(keywords)):\n",
    "\n",
    "        body_html += f'\\n<li>{keywords[i]}</li>'\n",
    "\n",
    "    body_html += '\\n</ul>'\n",
    "\n",
    "    if isinstance(row['Urls'], str):\n",
    "\n",
    "        all_images = row['Urls'].split(\",\")\n",
    "\n",
    "        first_image, *other_images = all_images\n",
    "\n",
    "    else:\n",
    "\n",
    "        continue\n",
    "\n",
    "    title = row['Title'] + \" \" + row['Code']\n",
    "    title = title.replace('\"', \"\")\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "\n",
    "    temp_extract = [row['Occasions'], row['Keywords'],  row['Tags']]\n",
    "\n",
    "    meta_sleeve_length_type = check_sleeve_preference(temp_extract)\n",
    "\n",
    "    # Create a new row for the main product entry\n",
    "\n",
    "    product_entry = {\n",
    "\n",
    "\n",
    "\n",
    "        'Handle': row['Code'].lower(),\n",
    "\n",
    "\n",
    "\n",
    "        'Title': title,\n",
    "\n",
    "\n",
    "\n",
    "        'Body (HTML)': body_html,\n",
    "\n",
    "\n",
    "\n",
    "        'Vendor': row['Brand'],\n",
    "\n",
    "\n",
    "\n",
    "        'Type': row['Dress Type'],  # You can customize this\n",
    "\n",
    "\n",
    "\n",
    "        'Tags': row['Tags'] + \",\" + row['Occasions'],\n",
    "\n",
    "\n",
    "\n",
    "        'Published': 'TRUE',\n",
    "\n",
    "\n",
    "\n",
    "        \"Product Category\": \"Apparel & Accessories > Clothing > Dresses\",\n",
    "\n",
    "\n",
    "\n",
    "        'Option1 Name': 'Size',\n",
    "\n",
    "\n",
    "\n",
    "        'Option1 Value': row['Size'],\n",
    "\n",
    "\n",
    "\n",
    "        'Option2 Name': 'Color',\n",
    "\n",
    "\n",
    "\n",
    "        'Option2 Value': row['Color'],\n",
    "\n",
    "\n",
    "\n",
    "        'Variant SKU': f\"{row['Code']}_{row['Color'].upper()}_{row['Size']}\",\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Grams': '',  # Add weight if available\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Inventory Tracker': 'shopify',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Inventory Qty': row['Quantity'],\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Inventory Policy': 'deny',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Fulfillment Service': 'manual',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Price': row['Price'],\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Compare at Price': '',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Requires Shipping': 'TRUE',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Taxable': 'TRUE',\n",
    "\n",
    "\n",
    "\n",
    "        'Variant Barcode': '',\n",
    "\n",
    "\n",
    "\n",
    "        'Image Src': first_image,  # First image URL\n",
    "\n",
    "\n",
    "\n",
    "        'Image Position': 1,\n",
    "\n",
    "\n",
    "\n",
    "        'Image Alt Text': row['Brand'] + \" \" + row['Code'].lower() + \" \" + row['Filename'],\n",
    "        'metafield.custom.clothing_features': meta_features,\n",
    "        'metafield.custom.dress_occasion': re.sub(r'\\s+', ' ', row['Occasions']),\n",
    "        'metafield.custom.dress_style': row['Code'].upper(),\n",
    "        'metafield.custom.skirt_dress_length_type': row['Dress Type'],\n",
    "        'metafield.custom.sleeve_length_type': meta_sleeve_length_type\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # Add the main product entry to the list\n",
    "\n",
    "    all_entries.append(pd.DataFrame([product_entry]))\n",
    "\n",
    "\n",
    "# Append additional images for the last code\n",
    "\n",
    "\n",
    "if other_images:\n",
    "\n",
    "    for idx, url in enumerate(other_images):\n",
    "\n",
    "        image_entry = {\n",
    "\n",
    "\n",
    "\n",
    "            'Handle': current_code.lower(),\n",
    "\n",
    "\n",
    "\n",
    "            'Image Src': url,\n",
    "\n",
    "\n",
    "\n",
    "            'Image Position': idx + 2,  # Start from position 2\n",
    "\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "        all_entries.append(pd.DataFrame([image_entry]))\n",
    "\n",
    "\n",
    "# Concatenate all entries into a single DataFrame\n",
    "\n",
    "\n",
    "shopify_df = pd.concat(all_entries, ignore_index=True)\n",
    "\n",
    "\n",
    "print(shopify_df['Handle'].nunique())\n",
    "output_file_path = '../../data/sheets/shopify_output_demo.csv'\n",
    "shopify_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Shopify CSV file has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some verificatiosn for understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "Total number of variants: 2383\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "# Replace with the actual file path\n",
    "file1_path = '../../data/sheets/step_5_output.csv'\n",
    "file2_path = '../../data/s3_url_images.csv'  # Replace with the actual file path\n",
    "\n",
    "file1 = pd.read_csv(file1_path)\n",
    "file2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Identify common codes between file1 and file2\n",
    "common_codes = set(file1['Code']).intersection(set(file2['Product Code']))\n",
    "print(len(common_codes))\n",
    "#\n",
    "# Filter file1 to include only rows with common codes\n",
    "filtered_file1 = file1[file1['Code'].isin(common_codes)]\n",
    "\n",
    "# Group by 'Code' and count unique combinations of 'Size' and 'Color'\n",
    "variant_counts = filtered_file1.groupby('Code').apply(lambda x: x[[\n",
    "    'Size', 'Color']].drop_duplicates().shape[0], include_groups=False).reset_index(name='Variant Count')\n",
    "\n",
    "# Print the variant counts\n",
    "# print(variant_counts)\n",
    "\n",
    "# Calculate the sum of the variant counts\n",
    "total_variants = variant_counts['Variant Count'].sum()\n",
    "\n",
    "# Print the total number of variants\n",
    "print(f\"Total number of variants: {total_variants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common codes: 314\n",
      "Unique codes in file1: 0\n",
      "set()\n",
      "Unique codes in file2: 8\n",
      "{'E2394', 'E1028', 'E2434', 'E1984', 'E2276', 'E2152', 'E2225', 'E1340'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "df1 = pd.read_csv('../../data/sheets/step_5_output.csv')\n",
    "df2 = pd.read_csv('../../data/s3_url_images.csv')\n",
    "\n",
    "# Convert the 'Code' column to sets for comparison\n",
    "set1 = set(df1['Code'])\n",
    "set2 = set(df2['Product Code'])\n",
    "\n",
    "# Find common and uncommon codes\n",
    "common_codes = set1.intersection(set2)\n",
    "unique_in_file1 = set1.difference(set2)\n",
    "unique_in_file2 = set2.difference(set1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Common codes: {len(common_codes)}\")\n",
    "# print(common_codes)\n",
    "\n",
    "print(f\"Unique codes in file1: {len(unique_in_file1)}\")\n",
    "print(unique_in_file1)\n",
    "\n",
    "print(f\"Unique codes in file2: {len(unique_in_file2)}\")\n",
    "print(unique_in_file2)\n",
    "\n",
    "# Optional: Create DataFrames for common and unique codes and save to new CSV files\n",
    "pd.DataFrame(common_codes, columns=['Code']).to_csv('common_codes.csv', index=False)\n",
    "pd.DataFrame(unique_in_file1, columns=['Code']).to_csv('unique_in_file1.csv', index=False)\n",
    "pd.DataFrame(unique_in_file2, columns=['Code']).to_csv('unique_in_file2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load-data-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
